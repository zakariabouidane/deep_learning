{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMuolSnT-uqw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iczK98W-_eRQ"
      },
      "outputs": [],
      "source": [
        "# Reading the dataset\n",
        "def read_dataset():\n",
        "  df = pd.read_csv(\"https://drive.google.com/file/d/1pQxtljlNVh0DHYg-Ye7dtpDTlFceHVfa/\")\n",
        "  #print(len(df.columns))\n",
        "  X = df[df.columns[0:60]].values\n",
        "  y = df[df.columns[60]].values\n",
        "\n",
        "  # Encode the dependent variable\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(y)\n",
        "  y = encoder.transform(y)\n",
        "  Y = one_hot_encode(y)\n",
        "  print(X.shape)\n",
        "  return(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TjeIvR_CVsV"
      },
      "outputs": [],
      "source": [
        "# Define the encoder function\n",
        "def one_hot_encode(labels):\n",
        "  n_labels = len(labels)\n",
        "  n_unique_labels = len (np.unique(labels))\n",
        "  one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
        "  one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "  return one_hot_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nYxHVpCD5IC",
        "outputId": "9d3a5f60-5c0b-4c31-8f92-0a33cf9cc2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(171, 60)\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset\n",
        "X, Y = read_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNBOPXklFNv-"
      },
      "outputs": [],
      "source": [
        "# Shuffle the dataset\n",
        "X, Y = shuffle(X, Y, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyG2eb8PGUTb"
      },
      "outputs": [],
      "source": [
        "# Convert the dataset into train and test part\n",
        "train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size=0.20, random_state=415)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIuLKwonHI0e",
        "outputId": "c63c3462-2832-4b28-d6a0-033e9f0489cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(136, 60)\n",
            "(136, 2)\n",
            "(35, 60)\n"
          ]
        }
      ],
      "source": [
        "# Inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaW42_-QHjl6",
        "outputId": "436c1a12-fb76-4966-a6e8-aaeb989bdaa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_dim 60\n"
          ]
        }
      ],
      "source": [
        "# Define the important parameters and variable to work with the tensors\n",
        "learning_rate = 0.3\n",
        "training_epochs = 1000\n",
        "cost_history = np.empty(shape=[1], dtype=float)\n",
        "n_dim = X.shape[1]\n",
        "print(\"n_dim\", n_dim)\n",
        "n_class = 2\n",
        "model_path = \"https://colab.research.google.com/drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOro92BQI7Tv"
      },
      "outputs": [],
      "source": [
        "# Define the # of hiden layers and # of neurons for each layer\n",
        "n_hidden_1 = 60\n",
        "n_hidden_2 = 60\n",
        "n_hidden_3 = 60\n",
        "n_hidden_4 = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3la90pvUKGir",
        "outputId": "a0e33a49-b711-40b1-f9da-59ab0912c289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "x = tf.placeholder(tf.float32, [None, n_dim])\n",
        "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))\n",
        "y_ = tf.placeholder(tf.float32, [None, n_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeNCCVOnLOlj"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "def multilayer_perceptron(x, weights, biases):\n",
        "  # Hidden layer with RELU activation\n",
        "\n",
        "  layer_1 = tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])\n",
        "  layer_1 = tf.nn.sigmoid(layer_1)\n",
        "\n",
        "  # Hidden layer with sigmoid activation\n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights[\"h2\"]), biases[\"b2\"])\n",
        "  layer_2 = tf.nn.sigmoid(layer_2)\n",
        "\n",
        "  # Hidden layer with sigmoid activation\n",
        "  layer_3 = tf.add(tf.matmul(layer_2, weights[\"h3\"]), biases[\"b3\"])\n",
        "  layer_3 = tf.nn.sigmoid(layer_3)\n",
        "\n",
        "  # Hidden layer with RELU activation\n",
        "  layer_4 = tf.add(tf.matmul(layer_3, weights[\"h4\"]), biases[\"b4\"])\n",
        "  layer_4 = tf.nn.relu(layer_4)\n",
        "\n",
        "  # Output layer linear activation\n",
        "  out_layer = tf.matmul(layer_4, weights[\"out\"]) + biases[\"out\"]\n",
        "  return out_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLw4-NbzLsoy"
      },
      "outputs": [],
      "source": [
        "weights = {\n",
        "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
        "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
        "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP_wCLwDRBJ0"
      },
      "outputs": [],
      "source": [
        "# Initialize all the variables\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver= tf.train.Saver()\n",
        "\n",
        "# Call your model defined\n",
        "y = multilayer_perceptron(x,weights, biases)\n",
        "\n",
        "# Define the cost function and optimizer\n",
        "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
        "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EMNg27AxS4aP",
        "outputId": "bdbefa37-0ff6-4fa3-be59-02e24b7441f6"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-116dc128c1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() takes no keyword arguments"
          ]
        }
      ],
      "source": [
        "# Calculate the cost and the accuracy for each epoch\n",
        "\n",
        "mse_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  sess.run(training_step, feed_dict={x: train_x, y: train_y})\n",
        "  cost = sess.run(cost_function, feed_dict={x: train_x, y: train_y})\n",
        "  cost_history = np.append(cost_history, cost)\n",
        "  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  pred_y = sess.run(y, feed_dict={x: test_x})\n",
        "  mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
        "  mse_ = sess.run(mse)\n",
        "  mse_history.append(mse_)\n",
        "  accuracy = {sess.run(accuracy, feed_dict={x: train_x, y_: train_y})}\n",
        "  accuracy_history.append(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-HrNbc6W-pb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NMI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}